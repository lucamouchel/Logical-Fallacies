{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/root/Logical-Fallacies/data/argotario/arguments-en-2018-01-15.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1344, 9)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Topic', 'Stance', 'Intended Fallacy', 'Text']]\n",
    "\n",
    "df['Intended Fallacy'].value_counts()\n",
    "test = df.sample(200, random_state=42)\n",
    "train = df.drop(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_data_train = train[train['Intended Fallacy'] == 'No Fallacy']\n",
    "sft_data_test = test[test['Intended Fallacy'] == 'No Fallacy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_data_train = train \n",
    "dpo_data_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i, entry in sft_data.iterrows():\n",
    "    stance = 'SUPPORTING' if entry['Stance'] == 'pro' else 'COUNTER'\n",
    "    prompt = f\"Generate a {stance} argument for the following topic: {entry['Topic']}\"\n",
    "    argument = entry['Text']\n",
    "    data.append({'prompt': prompt, 'argument': argument})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json \n",
    "\n",
    "# with open('/root/Logical-Fallacies/data/argotario/train.json', 'w') as f:\n",
    "#     json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.read_json('/root/Logical-Fallacies/data/argumentation/fallacies_arguments_support.json')\n",
    "counts = pd.read_csv('/root/Logical-Fallacies/data/LOGIC/edu_all.csv').updated_label.value_counts()\n",
    "fallacy_distributions = (counts/sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(topic, stance, fallacy_type):\n",
    "    data = examples[fallacy_type]\n",
    "    args = [data[f\"exampleArg1{stance}\"], data[f\"exampleArg2{stance}\"]]\n",
    "    fallacies = [data['example1'], data['example2']]\n",
    "    text =  f\"\"\"You are given a topic.  \n",
    "        Your task is to generate a {stance} argument in the form of a {fallacy_type} logical fallacy in the context of the topic. \n",
    "        It should not be longer than 20 words. \n",
    "        \n",
    "        {fallacy_type} fallacy is defined as: {examples[fallacy_type]['definition']}\n",
    "        examples of {fallacy_type} fallacy are: \n",
    "        {fallacies[0]}\n",
    "        {fallacies[1]}\n",
    "            \n",
    "        Here is an example of a supporting {fallacy_type} fallacy: \n",
    "        {args[0]}\n",
    "        \n",
    "        return the following using this json format. Do not forget quotation marks:\n",
    "        {\"{\"}\n",
    "            \"topic\": {topic},\n",
    "            \"fallacy type\": {fallacy_type},\n",
    "            \"{stance} fallacy\": ...\n",
    "        {\"}\"}\n",
    "        \"\"\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_anti_fallacy_prompt(fallacy_type, argument, topic, stance):\n",
    "    text = f\"\"\"The following argument is an example of a {fallacy_type} fallacy for the topic: {topic}.\n",
    "Argument: {argument}\n",
    "Generate a {stance} argument for this topic, by avoiding any fallacy pattern.\n",
    "You must return a simple argument that is not longer than 20 words in the following json format:\n",
    "    {\"{\"}\n",
    "        \"topic\": {topic},\n",
    "        \"fallacy type\": {fallacy_type},\n",
    "        \"{stance} argument\": ...\n",
    "    {\"}\"}\"\"\"\n",
    "    return text \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.error import RateLimitError, ServiceUnavailableError, APIError, APIConnectionError, Timeout, InvalidRequestError\n",
    "import openai\n",
    "import time\n",
    "openai.api_key = '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'\n",
    "def chat_completion(messages, model=\"gpt-3.5-turbo\", return_text=True, model_args=None):\n",
    "    if model_args is None:\n",
    "        model_args = {}\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(model=model, messages=messages, **model_args)\n",
    "            if return_text:\n",
    "                return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            return response\n",
    "        except (RateLimitError, ServiceUnavailableError, APIError, Timeout, InvalidRequestError, APIConnectionError) as e:\n",
    "            print(\"Timed out. Waiting for 1 minute.\")\n",
    "            time.sleep(60)\n",
    "            continue\n",
    "        \n",
    "def get_gpt_response(input_, model='gpt-3.5-turbo', i=0):\n",
    "    return chat_completion([{\"role\": \"assistant\", \"content\": input_}], model=model, return_text=True, model_args={\n",
    "                \"temperature\": 0.1,\n",
    "                \"max_tokens\": 150,\n",
    "                \"top_p\": 0.3,\n",
    "                \"frequency_penalty\": 0,\n",
    "                \"presence_penalty\": 0\n",
    "                })\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1144/1144 [42:22<00:00,  2.22s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "generated = []\n",
    "dpo_data = []\n",
    "for i, entry in tqdm(dpo_data_train.iterrows(), total=dpo_data_train.shape[0]):\n",
    "    stance = 'support' if entry['Stance'] == 'pro' else 'counter'\n",
    "    label = 'SUPPORTING' if entry['Stance'] == 'pro' else 'COUNTER'\n",
    "    dpo_prompt = f\"Generate a {label} argument for the following topic: {entry['Topic']}\"\n",
    "    argument = entry['Text']\n",
    "    topic = entry['Topic']\n",
    "    if entry['Intended Fallacy'] == 'No Fallacy':\n",
    "        chosen_fallacy_types = np.random.choice(fallacy_distributions.keys(), p=fallacy_distributions.values, size=2, replace=False)\n",
    "        chosen_sample = entry['Text']\n",
    "        for fallacy_type in (chosen_fallacy_types):\n",
    "            if fallacy_type=='miscellaneous':\n",
    "                continue\n",
    "            prompt = generate_prompt(topic, stance, fallacy_type)\n",
    "            try:\n",
    "                response = get_gpt_response(prompt)\n",
    "                response = json.loads(response)\n",
    "                rejected = response[f\"{stance} fallacy\"]\n",
    "                generated.append(response)\n",
    "                sample = {'prompt': dpo_prompt, 'chosen': chosen_sample, 'rejected': rejected}\n",
    "                dpo_data.append(sample)\n",
    "            except:\n",
    "                pathlib.Path('/root/Logical-Fallacies/data/argotario/').mkdir(parents=True, exist_ok=True)\n",
    "                output_path = '/root/Logical-Fallacies/data/argotario/generated_train.json'\n",
    "                with open(output_path, 'w') as json_file:\n",
    "                    json.dump(generated, json_file, indent=4, sort_keys=False)\n",
    "                    \n",
    "                pathlib.Path('/root/Logical-Fallacies/data/argotario/dpo/').mkdir(parents=True, exist_ok=True)\n",
    "                output_path = '/root/Logical-Fallacies/data/argotario/dpo/train.json'\n",
    "                with open(output_path, 'w') as json_file:\n",
    "                    json.dump(dpo_data, json_file, indent=4, sort_keys=False)\n",
    "                            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    elif entry['Intended Fallacy'] != 'No Fallacy':\n",
    "        rejected = entry['Text']\n",
    "        prompt = generate_anti_fallacy_prompt(entry['Intended Fallacy'], argument=argument, topic=topic, stance=stance)\n",
    "        try: \n",
    "            response = get_gpt_response(prompt)\n",
    "            response = json.loads(response)\n",
    "            chosen = response[f\"{stance} argument\"]\n",
    "            generated.append(response)\n",
    "            sample = {'prompt': dpo_prompt, 'chosen': chosen, 'rejected': rejected}\n",
    "            dpo_data.append(sample)\n",
    "        except:\n",
    "            pathlib.Path('/root/Logical-Fallacies/data/argotario/').mkdir(parents=True, exist_ok=True)\n",
    "            output_path = '/root/Logical-Fallacies/data/argotario/generated_train.json'\n",
    "            with open(output_path, 'w') as json_file:\n",
    "                json.dump(generated, json_file, indent=4, sort_keys=False)\n",
    "            \n",
    "            pathlib.Path('/root/Logical-Fallacies/data/argotario/dpo/').mkdir(parents=True, exist_ok=True)\n",
    "            output_path = '/root/Logical-Fallacies/data/argotario/dpo/train.json'\n",
    "            with open(output_path, 'w') as json_file:\n",
    "                json.dump(dpo_data, json_file, indent=4, sort_keys=False)\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "pathlib.Path('/root/Logical-Fallacies/data/argotario/dpo/').mkdir(parents=True, exist_ok=True)\n",
    "output_path = '/root/Logical-Fallacies/data/argotario/dpo/train.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(dpo_data, json_file, indent=4, sort_keys=False)\n",
    "            \n",
    "        \n",
    "pathlib.Path('/root/Logical-Fallacies/data/argotario/').mkdir(parents=True, exist_ok=True)\n",
    "output_path = '/root/Logical-Fallacies/data/argotario/generated_train.json'\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(generated, json_file, indent=4, sort_keys=False)\n",
    "    \n",
    "data.append({'prompt': prompt, 'chosen': argument})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
